**AlpacaEval**

[AlpacaEval](https://github.com/tatsu-lab/alpaca_eval): a single-turn benchmark which evaluates the helpfulness of chat and instruct models against `gpt-4` (Version 2).

### Install

```
cd alpaca_eval
pip install -e .
```

Note that the OpenAI requirements for MT-bench and AlpacaEval are different. If you use the same conda environment, please ensure you use `openai==1.30.1`.

### Models

TBD